{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPj3dtbFjKqifz51q1Fs852"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"tlA5lwkthK9I","executionInfo":{"status":"ok","timestamp":1716470185827,"user_tz":-180,"elapsed":1327,"user":{"displayName":"Abida Adra","userId":"05901109116663735606"}}},"outputs":[],"source":["import numpy as np\n","import random\n","from scipy.special import expit as activation_function\n","from scipy.stats import truncnorm\n","\n","def truncated_normal(mean=0, sd=1, low=0, upp=10):\n","  return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n","\n","class NeuralNetwork:\n","\n","  def __init__(self,no_of_in_nodes,no_of_out_nodes,no_of_hidden_nodes,learning_rate,bias=None):\n","    self.no_of_in_nodes = no_of_in_nodes\n","    self.no_of_out_nodes = no_of_out_nodes\n","    self.no_of_hidden_nodes = no_of_hidden_nodes\n","    self.learning_rate = learning_rate\n","    self.bias = bias\n","    self.create_weight_matrices()\n","\n","  def create_weight_matrices(self):\n","    X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n","    bias_node = 1 if self.bias else 0\n","    n = (self.no_of_in_nodes + bias_node) * self.no_of_hidden_nodes\n","    X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n","    self.wih = X.rvs(n).reshape((self.no_of_hidden_nodes,self.no_of_in_nodes + bias_node))\n","    n = (self.no_of_hidden_nodes + bias_node) * self.no_of_out_nodes\n","    X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n","    self.who = X.rvs(n).reshape((self.no_of_out_nodes,(self.no_of_hidden_nodes + bias_node)))\n","\n","  def dropout_weight_matrices(self,active_input_percentage=0.70,active_hidden_percentage=0.70):\n","    self.wih_orig = self.wih.copy()\n","    self.no_of_in_nodes_orig = self.no_of_in_nodes\n","    self.no_of_hidden_nodes_orig = self.no_of_hidden_nodes\n","    self.who_orig = self.who.copy()\n","    active_input_nodes = int(self.no_of_in_nodes * active_input_percentage)\n","    active_input_indices = sorted(random.sample(range(0, self.no_of_in_nodes),active_input_nodes))\n","    active_hidden_nodes = int(self.no_of_hidden_nodes * active_hidden_percentage)\n","    active_hidden_indices = sorted(random.sample(range(0, self.no_of_hidden_nodes),active_hidden_nodes))\n","    self.wih = self.wih[:, active_input_indices][active_hidden_indices]\n","    self.who = self.who[:, active_hidden_indices]\n","    self.no_of_hidden_nodes = active_hidden_nodes\n","    self.no_of_in_nodes = active_input_nodes\n","    return active_input_indices, active_hidden_indices\n","\n","  def weight_matrices_reset(self,active_input_indices,active_hidden_indices):\n","    temp = self.wih_orig.copy()[:,active_input_indices]\n","    temp[active_hidden_indices] = self.wih\n","    self.wih_orig[:, active_input_indices] = temp\n","    self.wih = self.wih_orig.copy()\n","    self.who_orig[:, active_hidden_indices] = self.who\n","    self.who = self.who_orig.copy()\n","    self.no_of_in_nodes = self.no_of_in_nodes_orig\n","    self.no_of_hidden_nodes = self.no_of_hidden_nodes_orig\n","\n","def train_single(self, input_vector, target_vector):\n","  if self.bias:\n","    input_vector = np.concatenate( (input_vector, [self.bias]) )\n","    input_vector = np.array(input_vector, ndmin=2).T\n","    target_vector = np.array(target_vector, ndmin=2).T\n","    output_vector1 = np.dot(self.wih, input_vector)\n","    output_vector_hidden = activation_function(output_vector1)\n","  if self.bias:\n","    output_vector_hidden = np.concatenate( (output_vector_hidden, [[self.bias]]) )\n","  output_vector2 = np.dot(self.who, output_vector_hidden)\n","  output_vector_network = activation_function(output_vector2)\n","  output_errors = target_vector - output_vector_network\n","\n","  tmp = output_errors * output_vector_network * (1.0 - output_vector_network)\n","  tmp = self.learning_rate * np.dot(tmp, output_vector_hidden.T)\n","  self.who += tmp\n","  hidden_errors = np.dot(self.who.T, output_errors)\n","  tmp = hidden_errors * output_vector_hidden * (1.0 - output_vector_hidden)\n","  if self.bias:\n","    x = np.dot(tmp, input_vector.T)[:-1,:]\n","  else:\n","    x = np.dot(tmp, input_vector.T)\n","  self.wih += self.learning_rate * x\n","\n","  def train(self, data_array,labels_one_hot_array,epochs=1,active_input_percentage=0.70,active_hidden_percentage=0.70,no_of_dropout_tests = 10):\n","    partition_length = int(len(data_array) / no_of_dropout_tests)\n","    for epoch in range(epochs):\n","      print(\"epoch: \", epoch)\n","      for start in range(0, len(data_array), partition_length):\n","        active_in_indices, active_hidden_indices = \\\n","    self.dropout_weight_matrices(active_input_percentage, active_hidden_percentage)\n","        for i in range(start, start + partition_length):\n","          self.train_single(data_array[i][active_in_indices],labels_one_hot_array[i])\n","        self.weight_matrices_reset(active_in_indices, active_hidden_indices)\n","\n","  def confusion_matrix(self, data_array, labels):\n","    cm = {}\n","    for i in range(len(data_array)):\n","      res = self.run(data_array[i])\n","      res_max = res.argmax()\n","      target = labels[i][0]\n","      if (target, res_max) in cm:\n","        cm[(target, res_max)] += 1\n","      else:\n","        cm[(target, res_max)] = 1\n","    return cm\n","\n","  def run(self, input_vector):\n","    if self.bias:\n","      input_vector = np.concatenate( (input_vector, [self.bias]) )\n","    input_vector = np.array(input_vector, ndmin=2).T\n","    output_vector = np.dot(self.wih, input_vector)\n","    output_vector = activation_function(output_vector)\n","\n","    if self.bias:\n","      output_vector = np.concatenate( (output_vector, [[self.bias]]) )\n","\n","    output_vector = np.dot(self.who, output_vector)\n","    output_vector = activation_function(output_vector)\n","    return output_vector\n","\n","  def evaluate(self, data, labels):\n","    corrects, wrongs = 0, 0\n","    for i in range(len(data)):\n","      res = self.run(data[i])\n","      res_max = res.argmax()\n","      if res_max == labels[i]:\n","        corrects += 1\n","      else:\n","        wrongs += 1\n","    return corrects, wrongs\n"]}]}