{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNGztOBx5VTQo9KLcxo5QH0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"r_smd-slm9DH","executionInfo":{"status":"ok","timestamp":1717175101597,"user_tz":-180,"elapsed":36,"user":{"displayName":"Abida Adra","userId":"05901109116663735606"}}},"outputs":[],"source":["import re\n","import os"]},{"cell_type":"code","source":["def dict_merge_sum(d1, d2):\n","  return { k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1) | set(d2) }\n","d1 = dict(a=4, b=5, d=8)\n","d2 = dict(a=1, d=10, e=9)\n","dict_merge_sum(d1, d2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVStUZP0nMDf","executionInfo":{"status":"ok","timestamp":1717175131986,"user_tz":-180,"elapsed":339,"user":{"displayName":"Abida Adra","userId":"05901109116663735606"}},"outputId":"5f5c0bc9-6dcf-422b-deab-7947beca5c54"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'b': 5, 'd': 18, 'e': 9, 'a': 5}"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["class BagOfWords(object):\n","  def __init__(self):\n","    self.__number_of_words = 0\n","    self.__bag_of_words = {}\n","\n","  def __add__(self, other):\n","    erg = BagOfWords()\n","    erg.__bag_of_words = dict_merge_sum(self.__bag_of_words,other.__bag_of_words)\n","    return erg\n","\n","  def add_word(self,word):\n","    self.__number_of_words += 1\n","    if word in self.__bag_of_words:\n","      self.__bag_of_words[word] += 1\n","    else:\n","      self.__bag_of_words[word] = 1\n","  def len(self):\n","\n","    return len(self.__bag_of_words)\n","  def Words(self):\n","    return self.__bag_of_words.keys()\n","\n","  def BagOfWords(self):\n","    return self.__bag_of_words\n","\n","  def WordFreq(self,word):\n","    if word in self.__bag_of_words:\n","      return self.__bag_of_words[word]\n","    else:\n","      return 0"],"metadata":{"id":"0svUwUUanYxc","executionInfo":{"status":"ok","timestamp":1717175315606,"user_tz":-180,"elapsed":343,"user":{"displayName":"Abida Adra","userId":"05901109116663735606"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class Document(object):\n","  _vocabulary = BagOfWords()\n","\n","  def __init__(self, vocabulary):\n","    self.__name = \"\"\n","    self.__document_class = None\n","    self._words_and_freq = BagOfWords()\n","    Document._vocabulary = vocabulary\n","\n","  def read_document(self,filename, learn=False):\n","    try:\n","      text = open(filename,\"r\", encoding='utf-8').read()\n","    except UnicodeDecodeError:\n","      text = open(filename,\"r\", encoding='latin-1').read()\n","\n","    text = text.lower()\n","    words = re.split(r\"\\W\",text)\n","\n","    self._number_of_words = 0\n","    for word in words:\n","      self._words_and_freq.add_word(word)\n","      if learn:\n","        Document._vocabulary.add_word(word)\n","\n","  def __add__(self,other):\n","\n","    res = Document(Document._vocabulary)\n","    res._words_and_freq = self._words_and_freq + other._words_and_freq\n","    return res\n","\n","  def vocabulary_length(self):\n","\n","    return len(Document._vocabulary)\n","\n","  def WordsAndFreq(self):\n","\n","    return self._words_and_freq.BagOfWords()\n","\n","  def Words(self):\n","\n","    d = self._words_and_freq.BagOfWords()\n","    return d.keys()\n","\n","  def WordFreq(self,word):\n","\n","    bow = self._words_and_freq.BagOfWords()\n","    if word in bow:\n","      return bow[word]\n","    else:\n","      return 0\n","\n","  def __and__(self, other):\n","\n","    intersection = []\n","    words1 = self.Words()\n","    for word in other.Words():\n","      if word in words1:\n","        intersection += [word]\n","    return intersection\n","\n"],"metadata":{"id":"5G2cUKVioJtx","executionInfo":{"status":"ok","timestamp":1717175674912,"user_tz":-180,"elapsed":561,"user":{"displayName":"Abida Adra","userId":"05901109116663735606"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class Category(Document):\n","  def __init__(self, vocabulary):\n","    Document.__init__(self, vocabulary)\n","    self._number_of_docs = 0\n","\n","  def Probability(self,word):\n","\n","    voc_len = Document._vocabulary.len()\n","    SumN = 0\n","    for i in range(voc_len):\n","      SumN = Category._vocabulary.WordFreq(word)\n","    N = self._words_and_freq.WordFreq(word)\n","    erg = 1 + N\n","    erg /= voc_len + SumN\n","    return erg\n","\n","  def __add__(self,other):\n","\n","    res = Category(self._vocabulary)\n","    res._words_and_freq = self._words_and_freq + other._words_and_freq\n","    return res\n","\n","  def SetNumberOfDocs(self, number):\n","    self._number_of_docs = number\n","\n","  def NumberOfDocuments(self):\n","    return self._number_of_docs\n"],"metadata":{"id":"LzPHuevxpcCM","executionInfo":{"status":"ok","timestamp":1717175796015,"user_tz":-180,"elapsed":690,"user":{"displayName":"Abida Adra","userId":"05901109116663735606"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class Pool(object):\n","  def __init__(self):\n","    self.__document_classes = {}\n","    self.__vocabulary = BagOfWords()\n","  def sum_words_in_class(self, dclass):\n","    sum = 0\n","    for word in self.__vocabulary.Words():\n","      WaF = self.__document_classes[dclass].WordsAndFreq()\n","      if word in WaF:\n","        sum += WaF[word]\n","    return sum\n","\n","  def learn(self, directory, dclass_name):\n","\n","    x = Category(self.__vocabulary)\n","    dir = os.listdir(directory)\n","    for file in dir:\n","      d = Document(self.__vocabulary)\n","      d.read_document(directory + \"/\" + file, learn = True)\n","      x = x + d\n","    self.__document_classes[dclass_name] = x\n","    x.SetNumberOfDocs(len(dir))\n","\n","  def Probability(self, doc, dclass = \"\"):\n","\n","    if dclass:\n","      sum_dclass = self.sum_words_in_class(dclass)\n","      prob = 0\n","      d = Document(self.__vocabulary)\n","      d.read_document(doc)\n","    for j in self.__document_classes:\n","      sum_j = self.sum_words_in_class(j)\n","      prod = 1\n","      for i in d.Words():\n","        wf_dclass = 1 + self.__document_classes[dclass].WordFreq(i)\n","        wf = 1 + self.__document_classes[j].WordFreq(i)\n","        r = wf * sum_dclass / (wf_dclass * sum_j)\n","        prod *= r\n","        prob += prod * self.__document_classes[j].NumberOfDocuments() / self.__document_classes[dclass].NumberOfDocuments()\n","      if prob != 0:\n","        return 1 / prob\n","      else:\n","        return -1\n","    else:\n","      prob_list = []\n","      for dclass in self.__document_classes:\n","        prob = self.Probability(doc, dclass)\n","        prob_list.append([dclass,prob])\n","      prob_list.sort(key = lambda x: x[1], reverse = True)\n","      return prob_list\n","\n","  def DocumentIntersectionWithClasses(self, doc_name):\n","    res = [doc_name]\n","    for dc in self.__document_classes:\n","      d = Document(self.__vocabulary)\n","      d.read_document(doc_name, learn=False)\n","      o = self.__document_classes[dc] & d\n","      intersection_ratio = len(o) / len(d.Words())\n","      res += (dc, intersection_ratio)\n","    return res\n","\n"],"metadata":{"id":"wUz6Oxmep_SX"},"execution_count":null,"outputs":[]}]}